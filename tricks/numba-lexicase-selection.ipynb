{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6050dfa4dc1b6",
   "metadata": {},
   "source": [
    "## Lexicase Selection Numba加速\n",
    "\n",
    "DEAP中Lexicase Selection的默认实现速度较慢。因此，我们可以尝试使用Numba来加速它。\n",
    "Numba的原理是将Python代码编译为LLVM中间代码，然后再编译为机器码。从而显著提高Python代码的运行速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59cfefc0467c74ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T03:39:37.866831400Z",
     "start_time": "2023-12-25T03:39:37.665471400Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "\n",
    "from deap import base, creator, tools, gp\n",
    "import time\n",
    "\n",
    "\n",
    "# 符号回归\n",
    "def evalSymbReg(individual, pset):\n",
    "    # 编译GP树为函数\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    \n",
    "    # 使用numpy创建一个向量\n",
    "    x = np.linspace(-10, 10, 100) \n",
    "    \n",
    "    return tuple((func(x) - x**2)**2)\n",
    "\n",
    "\n",
    "# 创建个体和适应度函数，适应度数组大小与数据量相同\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,) * 100)  # 假设我们有100个数据点\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "956e01e17271daa6",
   "metadata": {},
   "source": [
    "### 遗传算子\n",
    "在使用Numba进行对Lexicase加速时，只需要重写Lexicase函数，加上@njit(cache=True)这个注解就可以了。\n",
    "需要注意一些特殊的函数可能不受Numba支持，但所有基本的Python运算符都是支持的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5dbeab9190022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T03:39:37.891395500Z",
     "start_time": "2023-12-25T03:39:37.870837200Z"
    }
   },
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def selAutomaticEpsilonLexicaseNumba(case_values, fit_weights, k):\n",
    "    selected_individuals = []\n",
    "    avg_cases = 0\n",
    "\n",
    "    for i in range(k):\n",
    "        candidates = list(range(len(case_values)))\n",
    "        cases = np.arange(len(case_values[0]))\n",
    "        np.random.shuffle(cases)\n",
    "\n",
    "        while len(cases) > 0 and len(candidates) > 1:\n",
    "            errors_for_this_case = np.array(\n",
    "                [case_values[x][cases[0]] for x in candidates]\n",
    "            )\n",
    "            median_val = np.median(errors_for_this_case)\n",
    "            median_absolute_deviation = np.median(\n",
    "                np.array([abs(x - median_val) for x in errors_for_this_case])\n",
    "            )\n",
    "            if fit_weights > 0:\n",
    "                best_val_for_case = np.max(errors_for_this_case)\n",
    "                min_val_to_survive = best_val_for_case - median_absolute_deviation\n",
    "                candidates = list(\n",
    "                    [\n",
    "                        x\n",
    "                        for x in candidates\n",
    "                        if case_values[x][cases[0]] >= min_val_to_survive\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                best_val_for_case = np.min(errors_for_this_case)\n",
    "                max_val_to_survive = best_val_for_case + median_absolute_deviation\n",
    "                candidates = list(\n",
    "                    [\n",
    "                        x\n",
    "                        for x in candidates\n",
    "                        if case_values[x][cases[0]] <= max_val_to_survive\n",
    "                    ]\n",
    "                )\n",
    "            cases = np.delete(cases, 0)\n",
    "        avg_cases = (avg_cases * i + (len(case_values[0]) - len(cases))) / (i + 1)\n",
    "        selected_individuals.append(np.random.choice(np.array(candidates)))\n",
    "    return selected_individuals, avg_cases\n",
    "\n",
    "def selAutomaticEpsilonLexicaseFast(individuals, k):\n",
    "    fit_weights = individuals[0].fitness.weights[0]\n",
    "    case_values = np.array([ind.fitness.values for ind in individuals])\n",
    "    index, avg_cases = selAutomaticEpsilonLexicaseNumba(case_values, fit_weights, k)\n",
    "    selected_individuals = [individuals[i] for i in index]\n",
    "    return selected_individuals"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "783887f49d890b79",
   "metadata": {},
   "source": [
    "在定义好了新的Lexicase选择算子之后，在注册选择算子的时候，将新的选择算子注册进去就可以了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851794d4d36e3681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T03:39:37.964779400Z",
     "start_time": "2023-12-25T03:39:37.897670100Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "# 定义函数集合和终端集合\n",
    "pset = gp.PrimitiveSet(\"MAIN\", arity=1)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator.neg, 1)\n",
    "pset.addEphemeralConstant(\"rand101\", lambda: random.randint(-1, 1))\n",
    "pset.renameArguments(ARG0='x')\n",
    "\n",
    "# 定义遗传编程操作\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "toolbox.register(\"evaluate\", evalSymbReg, pset=pset)\n",
    "toolbox.register(\"select\", selAutomaticEpsilonLexicaseFast)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr, pset=pset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "62f30d17704db709",
   "metadata": {},
   "source": [
    "### 演化流程\n",
    "演化流程与传统符号回归相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515b587d4f8876ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T03:39:39.571928900Z",
     "start_time": "2023-12-25T03:39:37.971234500Z"
    }
   },
   "source": [
    "import numpy\n",
    "from deap import algorithms\n",
    "\n",
    "# 定义统计指标\n",
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats_size = tools.Statistics(len)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
    "mstats.register(\"avg\", numpy.mean)\n",
    "mstats.register(\"std\", numpy.std)\n",
    "mstats.register(\"min\", numpy.min)\n",
    "mstats.register(\"max\", numpy.max)\n",
    "\n",
    "# 使用Numba加速\n",
    "numba_lexicase_time = []\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    population = toolbox.population(n=100)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    pop, log  = algorithms.eaSimple(population=population,\n",
    "                               toolbox=toolbox, cxpb=0.9, mutpb=0.1, ngen=10, stats=mstats, halloffame=hof, verbose=True)\n",
    "    end = time.time()\n",
    "    print(str(hof[0]))\n",
    "    numba_lexicase_time.append(end - start)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "98efab3037e032ea",
   "metadata": {},
   "source": [
    "为了展示Numba加速的效果，我们将使用纯Python实现的Lexicase Selection进行对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1efd33d5f96a536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T03:45:33.479324Z",
     "start_time": "2023-12-25T03:39:39.565415500Z"
    }
   },
   "source": [
    "# 使用纯Python实现的Lexicase Selection\n",
    "toolbox.register(\"select\", tools.selAutomaticEpsilonLexicase)\n",
    "python_lexicase_time = []\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    population = toolbox.population(n=100)\n",
    "    hof = tools.HallOfFame(1)\n",
    "    pop, log  = algorithms.eaSimple(population=population,\n",
    "                               toolbox=toolbox, cxpb=0.9, mutpb=0.1, ngen=10, stats=mstats, halloffame=hof, verbose=True)\n",
    "    end = time.time()\n",
    "    print(str(hof[0]))\n",
    "    python_lexicase_time.append(end - start)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "adae32e725d21dcf",
   "metadata": {},
   "source": [
    "下面是Numba加速和纯Python实现的Lexicase Selection的运行时间对比。从结果可以看出，Numba加速后的Lexicase Selection的运行速度远优于纯Python实现的Lexicase Selection。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3caf7686fef519a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T03:45:33.641210400Z",
     "start_time": "2023-12-25T03:45:33.479324Z"
    }
   },
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {'Category': ['Numba Lexicase'] * len(numba_lexicase_time) + ['Python Lexicase'] * len(python_lexicase_time),\n",
    "     'Time': np.concatenate([numba_lexicase_time, python_lexicase_time])})\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(data=data, x='Category', y='Time', palette=\"Set3\", width=0.4)\n",
    "plt.title('Comparison of Numba and Pure Python')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Time')\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
